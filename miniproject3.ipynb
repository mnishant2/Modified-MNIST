{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "miniproject3new1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWzwBDPIiFbw",
        "colab_type": "code",
        "outputId": "90bf69bd-9830-4ba9-d375-40760c1c957e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLMD69hIib1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extract data\n",
        "# !unzip /content/drive/My\\ Drive/modified-mnist.zip -d /content/drive/My\\ Drive/modifiedmnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7246C-Yh87Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os,sys\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from collections import OrderedDict\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# from torch.functional.F import "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HHH_dhoIYnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tJEPxUifvfh",
        "colab_type": "code",
        "outputId": "e0020136-fdd6-4171-d5e6-3198962bfd02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "#need to install/update imgaug package\n",
        "!pip install -U git+https://github.com/aleju/imgaug.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/aleju/imgaug.git\n",
            "  Cloning https://github.com/aleju/imgaug.git to /tmp/pip-req-build-6wuk2wrd\n",
            "  Running command git clone -q https://github.com/aleju/imgaug.git /tmp/pip-req-build-6wuk2wrd\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug==0.3.0) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.3.0) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug==0.3.0) (1.3.2)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug==0.3.0) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug==0.3.0) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug==0.3.0) (0.15.0)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/dc/b250f03ab68068033fd2356428c1357431d8ebc6a26405098e0f27c94f7a/opencv_python_headless-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (22.1MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1MB 417kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug==0.3.0) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug==0.3.0) (1.6.4.post2)\n",
            "Requirement already satisfied, skipping upgrade: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->imgaug==0.3.0) (0.46)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.3.0) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.3.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.3.0) (2.4.5)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug==0.3.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug==0.3.0) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug==0.3.0) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.3.0) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug==0.3.0) (4.4.1)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.3.0-cp36-none-any.whl size=876731 sha256=cbeb1dba8b51dd6ad3eb8fdc34ecfdfed20e8c28ec9a23b347cff98c7370d17c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-79jcj6_n/wheels/65/3d/94/ee32cbeaa29c473a4db74c2d21904ac747311fdca4732665f0\n",
            "Successfully built imgaug\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python-headless, imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.3.0 opencv-python-headless-4.1.1.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTYXjav_F9DV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiNgqQVd26zn",
        "colab_type": "text"
      },
      "source": [
        "Loading and preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKg6vGqViC8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img=pd.read_pickle('/content/drive/My Drive/modifiedmnist/train_max_x')\n",
        "test_img=pd.read_pickle('/content/drive/My Drive/modifiedmnist/test_max_x')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBiiBH-dl8nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=pd.read_csv('/content/drive/My Drive/modifiedmnist/train_max_y.csv')\n",
        "del train_labels['Id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjGvARGmqZh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=np.array(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAGrwF5AD64N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=train_labels.reshape(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR3jN9WAqjVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(train_img,train_labels,test_size=0.2,random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "149LBBJiZrje",
        "colab_type": "code",
        "outputId": "8619fbac-1fc5-45f8-d4fe-815c032a7da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train= X_train.astype('uint8')\n",
        "X_val= X_val.astype('uint8')\n",
        "X_train.dtype"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMpffbSwZRob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_img=test_img.astype('uint8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2nk7Cl63MWy",
        "colab_type": "text"
      },
      "source": [
        "Creating a dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08SxobGsvI5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, target, transform=None,transform1=None):\n",
        "        self.data = data\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        self.transform1=transform1\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        \n",
        "        y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            \n",
        "            x = self.transform(x)\n",
        "            x=x.repeat(3,1,1)\n",
        "        if self.transform1:\n",
        "            x=self.transform1(x)\n",
        "#             print(x.shape)\n",
        "            # x.unsqueeze_(0)\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vplxTAH3HQJ",
        "colab_type": "text"
      },
      "source": [
        "Image Augmentation class of transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWnmq228GF7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImgAugTransform:\n",
        "  def __init__(self):\n",
        "    # we can change the amount of augmentation by adjusting the probability\n",
        "    self.aug = iaa.Sequential([iaa.Sometimes(0.5,iaa.Affine(\n",
        "            scale={\"x\": (0.8, 1.1), \"y\": (0.8, 1.1)}, \n",
        "            translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, \n",
        "            rotate=(-10, 10), \n",
        "            shear=(-10, 10),\n",
        "            order=[0, 1], \n",
        "            cval=(0, 255),\n",
        "            mode='wrap' \n",
        "        )),iaa.Sometimes(0.6,iaa.OneOf([\n",
        "                    iaa.GaussianBlur((0, 2.0)), # blur images with a sigma between 0 and 3.0\n",
        "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=False),\n",
        "                    iaa.Dropout((0.01, 0.1), per_channel=False),\n",
        "                    iaa.Add((-10, 10), per_channel=False), # blur image using local means with kernel sizes between 2 and 7\n",
        "                    iaa.edges.Canny(alpha=0.5,hysteresis_thresholds=(60, 140), sobel_kernel_size=3,colorizer=iaa.RandomColorsBinaryImageColorizer(color_true=255,color_false=0)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                ])),\n",
        "        ],random_order=True)\n",
        "      \n",
        "  def __call__(self, img):\n",
        "#     img = np.array(img)\n",
        "    return self.aug.augment_image(img)\n",
        "    # iaa.Sometimes(0.2,iaa.Affine(rotate=(-20, 20), mode='edge'))\n",
        "    # iaa.GaussianBlur(sigma=0.5),"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0NZpbfXGcPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms1=torchvision.transforms.Compose([\n",
        "    ImgAugTransform(),                                        \n",
        "    torchvision.transforms.ToPILImage(),\n",
        "    torchvision.transforms.Resize(224, interpolation=2),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    \n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV6GByp9d5b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms2=torchvision.transforms.Compose([\n",
        "    #ImgAugTransform(),\n",
        "    torchvision.transforms.ToPILImage(),\n",
        "    torchvision.transforms.Resize(224, interpolation=2),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    \n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYZryq14KuRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms3=transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr35-aFa3ZLO",
        "colab_type": "text"
      },
      "source": [
        "Defining Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h01cwZlcynrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traindataset = MyDataset(X_train, y_train,transform=transforms1,transform1=transforms3)\n",
        "trainloader = DataLoader(\n",
        "    traindataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyiI0qCW0q_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valdataset = MyDataset(X_val, y_val,transform=transforms2,transform1=transforms3)\n",
        "valloader = DataLoader(\n",
        "    valdataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Crbn0KM8QgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dset_sizes={}\n",
        "dset_sizes['train']=X_train.shape[0]\n",
        "dset_sizes['val']=X_val.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs9U2MNl3j8j",
        "colab_type": "text"
      },
      "source": [
        "The model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U-rQTX_zFiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=1):\n",
        "        super(MyResNet, self).__init__()\n",
        "\n",
        "        # bring resnet\n",
        "        self.model = torchvision.models.resnet50(pretrained=True)\n",
        "        # for param in self.model.parameters():\n",
        "        #     param.requires_grad = False\n",
        "        # self.model.classifier[6] = nn.Linear(4096,10)\n",
        "        n_inputs = self.model.fc.in_features\n",
        "        classifier = nn.Sequential(\n",
        "                      nn.Linear(n_inputs, 512), \n",
        "                      nn.ReLU(), \n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(512, 10))\n",
        "      \n",
        "        self.model.fc = classifier\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bI5bht5TXAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtRQsaemTXFA",
        "colab_type": "code",
        "outputId": "55a0e66c-39b3-49ba-854b-9ddc944c2c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model=MyResNet()\n",
        "model=model.to(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/checkpoints/resnet101-5d3b4d8f.pth\n",
            "100%|██████████| 170M/170M [00:00<00:00, 203MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GREMzZuU3oNf",
        "colab_type": "text"
      },
      "source": [
        "IN CASE YOU NEED TO TEST EFFICIENTNET."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhiweTv98dmd",
        "colab_type": "code",
        "outputId": "d8a46a18-d668-4e57-fbf8-ae9d34c81ac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# ! pip install --upgrade efficientnet-pytorch"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: efficientnet-pytorch in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet-pytorch) (1.3.1+cu100)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet-pytorch) (1.17.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfXzM05c8v_X",
        "colab_type": "code",
        "outputId": "8d8ad647-7f1a-40e8-bc88-a7761f7c18ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# def efficientnet(version,num_classes):\n",
        "#     model = EfficientNet.from_pretrained('efficientnet-b{}'.format(version), num_classes=num_classes)\n",
        "#     num_ftrs = model._fc.in_features\n",
        "#     model._fc = nn.Linear(num_ftrs, num_classes)\n",
        "#     return model.cuda()\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "# model = efficientnet(5,10)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JckFzske3um-",
        "colab_type": "text"
      },
      "source": [
        "Defining hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRlWR54o3QeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "n_epochs=40\n",
        "learning_rate=0.01\n",
        "# optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1,patience=2,verbose=True)\n",
        "use_gpu=torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jttgry5W7y9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, filename):\n",
        "    print (\"=> Saving a new best\")\n",
        "    torch.save(state, filename) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7MYogppTW7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model = model\n",
        "    best_acc = 0.0\n",
        "    best_loss=1.0\n",
        "    # run for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                #optimizer = lr_scheduler(optimizer, epoch)\n",
        "                model.train(True)  # Set model to training mode\n",
        "            else:\n",
        "                model.train(False)  # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            total=0\n",
        "            correct=0\n",
        "            if phase == 'train':\n",
        "                phase_ = trainloader\n",
        "            else:\n",
        "                phase_ = valloader\n",
        "\n",
        "            # Run through all data in mini batches\n",
        "            for idx,data in enumerate(phase_):\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "#                 print(labels)\n",
        "                # wrap them in Variable\n",
        "                if use_gpu:\n",
        "                    inputs, labels = Variable(inputs.cuda()), \\\n",
        "                        Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward pass\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "                # calculating the loss\n",
        "#                 print(outputs,labels)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # statistics for printing\n",
        "                #running_loss += loss.data[0]\n",
        "                running_loss += loss.item()\n",
        "                total += labels.size(0)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                if idx%100==0 and idx>0:\n",
        "                  print(\"accuracy={}\".format(100*correct/total))\n",
        "\n",
        "            epoch_loss = running_loss / dset_sizes[phase]\n",
        "            # if phase == 'val':\n",
        "            #   val_loss=epoch_loss\n",
        "            epoch_acc = running_corrects / dset_sizes[phase]\n",
        "            new_acc=100*correct/total\n",
        "            print('{} Loss: {:.4f} {} Acc: {:.4f}'.format(phase,epoch_loss,phase,new_acc))\n",
        "\n",
        "            # save model if it performed better than\n",
        "            # any other previous model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_acc = epoch_acc\n",
        "                best_loss=epoch_loss\n",
        "                best_model = copy.deepcopy(model)\n",
        "                filename='/content/drive/My Drive/res50_'+str(epoch)+'.pth.tar'\n",
        "                save_checkpoint({\n",
        "                'epoch': epoch,\n",
        "                'state_dict': model.state_dict(),\n",
        "                'best_accuracy': best_acc,\n",
        "                'best_loss':best_loss,\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "                },filename)\n",
        "            elif phase=='val' and epoch_loss> best_loss:\n",
        "                print('model did not improve from {:.4f} val loss'.format(best_loss))\n",
        "        scheduler.step(epoch_loss)    \n",
        "        print()\n",
        "        \n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    return best_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsPgnv8O3zkI",
        "colab_type": "text"
      },
      "source": [
        "RUN MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeaNqp1UTW4r",
        "colab_type": "code",
        "outputId": "163299ee-0989-4527-9dc7-ab5793e69dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_conv = train_model(model, criterion, optimizer, num_epochs=n_epochs)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/39\n",
            "----------\n",
            "accuracy=37.46905940594059\n",
            "accuracy=51.694651741293534\n",
            "accuracy=58.959717607973424\n",
            "accuracy=63.81701995012469\n",
            "accuracy=67.35903193612775\n",
            "accuracy=69.9355241264559\n",
            "accuracy=72.03994293865905\n",
            "accuracy=73.57990012484395\n",
            "accuracy=74.8196448390677\n",
            "accuracy=76.12075424575424\n",
            "accuracy=77.16564486830154\n",
            "accuracy=77.98449208992507\n",
            "train Loss: 0.0220 train Acc: 78.3075\n",
            "accuracy=92.20297029702971\n",
            "accuracy=92.63059701492537\n",
            "accuracy=92.88828903654485\n",
            "val Loss: 0.0073 val Acc: 92.8300\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 1/39\n",
            "----------\n",
            "accuracy=89.63490099009901\n",
            "accuracy=88.8837064676617\n",
            "accuracy=89.30647840531562\n",
            "accuracy=89.26122194513715\n",
            "accuracy=89.42739520958084\n",
            "accuracy=89.70985856905158\n",
            "accuracy=89.75570613409415\n",
            "accuracy=89.84472534332085\n",
            "accuracy=90.12208657047725\n",
            "accuracy=90.40646853146853\n",
            "accuracy=90.5057901907357\n",
            "accuracy=90.65101998334721\n",
            "train Loss: 0.0103 train Acc: 90.7400\n",
            "accuracy=95.42079207920793\n",
            "accuracy=95.4912935323383\n",
            "accuracy=95.45265780730897\n",
            "val Loss: 0.0050 val Acc: 95.4900\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 2/39\n",
            "----------\n",
            "accuracy=93.03836633663366\n",
            "accuracy=92.91044776119404\n",
            "accuracy=92.9921096345515\n",
            "accuracy=92.87718204488777\n",
            "accuracy=92.96407185628742\n",
            "accuracy=92.92325291181365\n",
            "accuracy=92.90745363766048\n",
            "accuracy=92.8292759051186\n",
            "accuracy=92.9245283018868\n",
            "accuracy=93.01323676323676\n",
            "accuracy=93.03757947320618\n",
            "accuracy=93.02664446294754\n",
            "train Loss: 0.0077 train Acc: 93.0825\n",
            "accuracy=95.97772277227723\n",
            "accuracy=95.81778606965175\n",
            "accuracy=95.9406146179402\n",
            "val Loss: 0.0046 val Acc: 95.9400\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 3/39\n",
            "----------\n",
            "accuracy=94.05940594059406\n",
            "accuracy=94.23196517412936\n",
            "accuracy=94.2171926910299\n",
            "accuracy=94.18640897755611\n",
            "accuracy=94.15543912175649\n",
            "accuracy=94.11917637271215\n",
            "accuracy=94.08880171184023\n",
            "accuracy=94.1128277153558\n",
            "accuracy=94.11417869034406\n",
            "accuracy=94.14335664335664\n",
            "accuracy=94.26941416893733\n",
            "accuracy=94.32243963363864\n",
            "train Loss: 0.0065 train Acc: 94.3050\n",
            "accuracy=94.2759900990099\n",
            "accuracy=94.49626865671642\n",
            "accuracy=94.61171096345515\n",
            "val Loss: 0.0053 val Acc: 94.6800\n",
            "model did not improve from 0.0046 val loss\n",
            "\n",
            "Epoch 4/39\n",
            "----------\n",
            "accuracy=94.8019801980198\n",
            "accuracy=94.83830845771145\n",
            "accuracy=94.94393687707641\n",
            "accuracy=94.93453865336659\n",
            "accuracy=95.08483033932136\n",
            "accuracy=95.04471713810317\n",
            "accuracy=95.00713266761768\n",
            "accuracy=95.06866416978777\n",
            "accuracy=95.15468923418425\n",
            "accuracy=95.12050449550449\n",
            "accuracy=95.12091280653951\n",
            "accuracy=95.11604912572857\n",
            "train Loss: 0.0055 train Acc: 95.1025\n",
            "accuracy=95.91584158415841\n",
            "accuracy=95.95771144278606\n",
            "accuracy=96.22093023255815\n",
            "val Loss: 0.0039 val Acc: 96.2600\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 5/39\n",
            "----------\n",
            "accuracy=94.58539603960396\n",
            "accuracy=94.7294776119403\n",
            "accuracy=94.89202657807309\n",
            "accuracy=95.03584788029926\n",
            "accuracy=95.07235528942115\n",
            "accuracy=95.02911813643927\n",
            "accuracy=95.14532810271041\n",
            "accuracy=95.24032459425717\n",
            "accuracy=95.3072974472808\n",
            "accuracy=95.33591408591408\n",
            "accuracy=95.29121253405995\n",
            "accuracy=95.32681099084097\n",
            "train Loss: 0.0051 train Acc: 95.3275\n",
            "accuracy=97.61757425742574\n",
            "accuracy=97.37251243781094\n",
            "accuracy=97.41486710963456\n",
            "val Loss: 0.0029 val Acc: 97.4100\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 6/39\n",
            "----------\n",
            "accuracy=95.69925742574257\n",
            "accuracy=95.8955223880597\n",
            "accuracy=96.00290697674419\n",
            "accuracy=95.86190773067332\n",
            "accuracy=95.92689620758483\n",
            "accuracy=95.95985856905158\n",
            "accuracy=96.00570613409415\n",
            "accuracy=96.0362047440699\n",
            "accuracy=95.81714761376249\n",
            "accuracy=95.72927072927072\n",
            "accuracy=95.76237511353315\n",
            "accuracy=95.81598667776852\n",
            "train Loss: 0.0047 train Acc: 95.8300\n",
            "accuracy=97.27722772277228\n",
            "accuracy=97.2636815920398\n",
            "accuracy=97.39410299003322\n",
            "val Loss: 0.0030 val Acc: 97.4200\n",
            "model did not improve from 0.0029 val loss\n",
            "\n",
            "Epoch 7/39\n",
            "----------\n",
            "accuracy=95.79207920792079\n",
            "accuracy=96.00435323383084\n",
            "accuracy=96.18978405315615\n",
            "accuracy=96.2281795511222\n",
            "accuracy=96.20758483033931\n",
            "accuracy=96.1574459234609\n",
            "accuracy=96.1706490727532\n",
            "accuracy=96.09862671660424\n",
            "accuracy=96.17092119866814\n",
            "accuracy=96.12887112887113\n",
            "accuracy=96.04620799273388\n",
            "accuracy=96.02674854288094\n",
            "train Loss: 0.0044 train Acc: 96.0400\n",
            "accuracy=97.58663366336634\n",
            "accuracy=97.34141791044776\n",
            "accuracy=97.50830564784053\n",
            "val Loss: 0.0027 val Acc: 97.5100\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 8/39\n",
            "----------\n",
            "accuracy=96.72029702970298\n",
            "accuracy=96.5018656716418\n",
            "accuracy=96.4078073089701\n",
            "accuracy=96.34507481296758\n",
            "accuracy=96.50074850299401\n",
            "accuracy=96.57341930116472\n",
            "accuracy=96.53619828815977\n",
            "accuracy=96.63311485642946\n",
            "accuracy=96.60793562708102\n",
            "accuracy=96.63461538461539\n",
            "accuracy=96.60535876475932\n",
            "accuracy=96.5913821815154\n",
            "train Loss: 0.0039 train Acc: 96.5650\n",
            "accuracy=97.71039603960396\n",
            "accuracy=97.82338308457712\n",
            "accuracy=97.73671096345515\n",
            "val Loss: 0.0024 val Acc: 97.7200\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 9/39\n",
            "----------\n",
            "accuracy=97.02970297029702\n",
            "accuracy=96.65733830845771\n",
            "accuracy=96.70888704318936\n",
            "accuracy=96.69576059850374\n",
            "accuracy=96.71906187624751\n",
            "accuracy=96.64621464226289\n",
            "accuracy=96.60752496433666\n",
            "accuracy=96.55508739076154\n",
            "accuracy=96.57672031076582\n",
            "accuracy=96.61276223776224\n",
            "accuracy=96.6394187102634\n",
            "accuracy=96.65122814321398\n",
            "train Loss: 0.0036 train Acc: 96.6825\n",
            "accuracy=97.86509900990099\n",
            "accuracy=97.90111940298507\n",
            "accuracy=97.87167774086379\n",
            "val Loss: 0.0023 val Acc: 97.8800\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 10/39\n",
            "----------\n",
            "accuracy=97.12252475247524\n",
            "accuracy=96.95273631840796\n",
            "accuracy=97.00996677740864\n",
            "accuracy=96.9139650872818\n",
            "accuracy=96.89995009980039\n",
            "accuracy=96.8853993344426\n",
            "accuracy=96.92403708987162\n",
            "accuracy=96.81257802746566\n",
            "accuracy=96.83684794672585\n",
            "accuracy=96.82192807192807\n",
            "accuracy=96.80120345140782\n",
            "accuracy=96.84377601998335\n",
            "train Loss: 0.0034 train Acc: 96.8500\n",
            "accuracy=98.29826732673267\n",
            "accuracy=98.21206467661692\n",
            "accuracy=97.9858803986711\n",
            "val Loss: 0.0022 val Acc: 98.0300\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 11/39\n",
            "----------\n",
            "accuracy=97.24628712871286\n",
            "accuracy=97.29477611940298\n",
            "accuracy=97.40448504983388\n",
            "accuracy=97.2178927680798\n",
            "accuracy=97.24301397205589\n",
            "accuracy=97.18178036605657\n",
            "accuracy=97.16030670470757\n",
            "accuracy=97.14419475655431\n",
            "accuracy=97.0969755826859\n",
            "accuracy=97.07792207792208\n",
            "accuracy=97.08787465940054\n",
            "accuracy=97.06494587843464\n",
            "train Loss: 0.0032 train Acc: 97.0725\n",
            "accuracy=98.17450495049505\n",
            "accuracy=98.2431592039801\n",
            "accuracy=98.1312292358804\n",
            "val Loss: 0.0024 val Acc: 98.1100\n",
            "model did not improve from 0.0022 val loss\n",
            "\n",
            "Epoch 12/39\n",
            "----------\n",
            "accuracy=96.93688118811882\n",
            "accuracy=96.98383084577114\n",
            "accuracy=97.35257475083057\n",
            "accuracy=97.33478802992519\n",
            "accuracy=97.19311377245509\n",
            "accuracy=97.24937603993344\n",
            "accuracy=97.2672967189729\n",
            "accuracy=97.24953183520599\n",
            "accuracy=97.16981132075472\n",
            "accuracy=97.18718781218782\n",
            "accuracy=97.17870118074478\n",
            "accuracy=97.17943380516236\n",
            "train Loss: 0.0031 train Acc: 97.1650\n",
            "accuracy=97.58663366336634\n",
            "accuracy=97.66791044776119\n",
            "accuracy=97.76785714285714\n",
            "val Loss: 0.0023 val Acc: 97.8100\n",
            "model did not improve from 0.0022 val loss\n",
            "\n",
            "Epoch 13/39\n",
            "----------\n",
            "accuracy=97.77227722772277\n",
            "accuracy=97.55907960199005\n",
            "accuracy=97.35257475083057\n",
            "accuracy=97.35037406483791\n",
            "accuracy=97.41766467065868\n",
            "accuracy=97.3429700499168\n",
            "accuracy=97.2672967189729\n",
            "accuracy=97.23392634207241\n",
            "accuracy=97.24958379578247\n",
            "accuracy=97.26523476523477\n",
            "accuracy=97.29507266121708\n",
            "accuracy=97.3199417152373\n",
            "train Loss: 0.0030 train Acc: 97.3375\n",
            "accuracy=98.08168316831683\n",
            "accuracy=97.97885572139303\n",
            "accuracy=98.05855481727575\n",
            "val Loss: 0.0024 val Acc: 98.1000\n",
            "model did not improve from 0.0022 val loss\n",
            "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
            "\n",
            "Epoch 14/39\n",
            "----------\n",
            "accuracy=97.52475247524752\n",
            "accuracy=97.73009950248756\n",
            "accuracy=97.86129568106313\n",
            "accuracy=97.95043640897755\n",
            "accuracy=97.97904191616766\n",
            "accuracy=98.03972545757071\n",
            "accuracy=98.07417974322397\n",
            "accuracy=98.11953807740325\n",
            "accuracy=98.15482796892341\n",
            "accuracy=98.16121378621379\n",
            "accuracy=98.18346957311535\n",
            "accuracy=98.18900915903414\n",
            "train Loss: 0.0020 train Acc: 98.1975\n",
            "accuracy=98.88613861386139\n",
            "accuracy=98.80286069651741\n",
            "accuracy=98.75415282392026\n",
            "val Loss: 0.0015 val Acc: 98.7300\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 15/39\n",
            "----------\n",
            "accuracy=98.11262376237623\n",
            "accuracy=98.08768656716418\n",
            "accuracy=98.3077242524917\n",
            "accuracy=98.35567331670823\n",
            "accuracy=98.41566866267465\n",
            "accuracy=98.41410149750416\n",
            "accuracy=98.38177603423681\n",
            "accuracy=98.36142322097378\n",
            "accuracy=98.39761376248613\n",
            "accuracy=98.40784215784215\n",
            "accuracy=98.39350590372389\n",
            "accuracy=98.39716902581182\n",
            "train Loss: 0.0017 train Acc: 98.4000\n",
            "accuracy=98.51485148514851\n",
            "accuracy=98.6318407960199\n",
            "accuracy=98.77491694352159\n",
            "val Loss: 0.0015 val Acc: 98.7700\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 16/39\n",
            "----------\n",
            "accuracy=98.20544554455445\n",
            "accuracy=98.2587064676617\n",
            "accuracy=98.40116279069767\n",
            "accuracy=98.39463840399003\n",
            "accuracy=98.41566866267465\n",
            "accuracy=98.42970049916805\n",
            "accuracy=98.44418687589159\n",
            "accuracy=98.49016853932584\n",
            "accuracy=98.50860155382908\n",
            "accuracy=98.51086413586414\n",
            "accuracy=98.50703905540418\n",
            "accuracy=98.51165695253955\n",
            "train Loss: 0.0016 train Acc: 98.5150\n",
            "accuracy=98.91707920792079\n",
            "accuracy=98.8339552238806\n",
            "accuracy=98.97217607973423\n",
            "val Loss: 0.0014 val Acc: 98.9500\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 17/39\n",
            "----------\n",
            "accuracy=98.51485148514851\n",
            "accuracy=98.52300995024876\n",
            "accuracy=98.54651162790698\n",
            "accuracy=98.55049875311721\n",
            "accuracy=98.52170658682634\n",
            "accuracy=98.5440931780366\n",
            "accuracy=98.51997146932953\n",
            "accuracy=98.51747815230961\n",
            "accuracy=98.52941176470588\n",
            "accuracy=98.53896103896103\n",
            "accuracy=98.53258401453225\n",
            "accuracy=98.53767693588676\n",
            "train Loss: 0.0015 train Acc: 98.5400\n",
            "accuracy=98.76237623762377\n",
            "accuracy=98.75621890547264\n",
            "accuracy=98.9202657807309\n",
            "val Loss: 0.0014 val Acc: 98.9300\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 18/39\n",
            "----------\n",
            "accuracy=98.73143564356435\n",
            "accuracy=98.74067164179104\n",
            "accuracy=98.72300664451828\n",
            "accuracy=98.71415211970074\n",
            "accuracy=98.63398203592814\n",
            "accuracy=98.65848585690516\n",
            "accuracy=98.71166191155493\n",
            "accuracy=98.73205368289638\n",
            "accuracy=98.71670366259711\n",
            "accuracy=98.72315184815184\n",
            "accuracy=98.68585376930064\n",
            "accuracy=98.68599084096586\n",
            "train Loss: 0.0014 train Acc: 98.7050\n",
            "accuracy=99.16460396039604\n",
            "accuracy=99.06716417910448\n",
            "accuracy=98.97217607973423\n",
            "val Loss: 0.0014 val Acc: 98.9700\n",
            "=> Saving a new best\n",
            "\n",
            "Epoch 19/39\n",
            "----------\n",
            "accuracy=98.60767326732673\n",
            "accuracy=98.58519900497512\n",
            "accuracy=98.72300664451828\n",
            "accuracy=98.68298004987531\n",
            "accuracy=98.73378243512974\n",
            "accuracy=98.72608153078203\n",
            "accuracy=98.70274607703281\n",
            "accuracy=98.72425093632958\n",
            "accuracy=98.68895671476137\n",
            "accuracy=98.70754245754246\n",
            "accuracy=98.70288374205268\n",
            "accuracy=98.70160283097418\n",
            "train Loss: 0.0014 train Acc: 98.6900\n",
            "accuracy=99.00990099009901\n",
            "accuracy=98.94278606965175\n",
            "accuracy=98.90988372093024\n",
            "val Loss: 0.0014 val Acc: 98.9500\n",
            "model did not improve from 0.0014 val loss\n",
            "\n",
            "Epoch 20/39\n",
            "----------\n",
            "accuracy=98.76237623762377\n",
            "accuracy=98.55410447761194\n",
            "accuracy=98.65033222591362\n",
            "accuracy=98.65180798004988\n",
            "accuracy=98.70259481037924\n",
            "accuracy=98.70008319467554\n",
            "accuracy=98.67599857346647\n",
            "accuracy=98.66963171036205\n",
            "accuracy=98.68895671476137\n",
            "accuracy=98.7169080919081\n",
            "accuracy=98.70004541326067\n",
            "accuracy=98.71201082431307\n",
            "train Loss: 0.0013 train Acc: 98.7100\n",
            "accuracy=98.97896039603961\n",
            "accuracy=98.92723880597015\n",
            "accuracy=98.93064784053156\n",
            "val Loss: 0.0014 val Acc: 98.9200\n",
            "model did not improve from 0.0014 val loss\n",
            "\n",
            "Epoch 21/39\n",
            "----------\n",
            "accuracy=98.48391089108911\n",
            "accuracy=98.67848258706468\n",
            "accuracy=98.76453488372093\n",
            "accuracy=98.70635910224439\n",
            "accuracy=98.74625748502994\n",
            "accuracy=98.75727953410981\n",
            "accuracy=98.74286733238232\n",
            "accuracy=98.75546192259675\n",
            "accuracy=98.75832408435072\n",
            "accuracy=98.75124875124875\n",
            "accuracy=98.76816530426885\n",
            "accuracy=98.7770607826811\n",
            "train Loss: 0.0013 train Acc: 98.7975\n",
            "accuracy=99.10272277227723\n",
            "accuracy=99.06716417910448\n",
            "accuracy=98.93064784053156\n",
            "val Loss: 0.0014 val Acc: 98.9200\n",
            "model did not improve from 0.0014 val loss\n",
            "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
            "\n",
            "Epoch 22/39\n",
            "----------\n",
            "accuracy=98.76237623762377\n",
            "accuracy=98.94278606965175\n",
            "accuracy=98.94102990033223\n",
            "accuracy=98.92456359102245\n",
            "accuracy=98.89595808383234\n",
            "accuracy=98.89767054908486\n",
            "accuracy=98.8944365192582\n",
            "accuracy=98.90761548064918\n",
            "accuracy=98.91786903440621\n",
            "accuracy=98.90734265734265\n",
            "accuracy=98.9044050862852\n",
            "accuracy=98.87853871773522\n",
            "train Loss: 0.0012 train Acc: 98.8625\n",
            "accuracy=98.70049504950495\n",
            "accuracy=98.89614427860697\n",
            "accuracy=98.93064784053156\n",
            "val Loss: 0.0015 val Acc: 98.9100\n",
            "model did not improve from 0.0014 val loss\n",
            "\n",
            "Epoch 23/39\n",
            "----------\n",
            "accuracy=98.66955445544555\n",
            "accuracy=98.78731343283582\n",
            "accuracy=98.86835548172758\n",
            "accuracy=98.893391521197\n",
            "accuracy=98.83358283433134\n",
            "accuracy=98.8248752079867\n",
            "accuracy=98.84539942938659\n",
            "accuracy=98.82178526841449\n",
            "accuracy=98.8242230854606\n",
            "accuracy=98.83241758241758\n",
            "accuracy=98.81357856494097\n",
            "accuracy=98.80047876769359\n",
            "train Loss: 0.0013 train Acc: 98.8000\n",
            "accuracy=98.70049504950495\n",
            "accuracy=98.89614427860697\n",
            "accuracy=98.89950166112956\n",
            "val Loss: 0.0014 val Acc: 98.9100\n",
            "model did not improve from 0.0014 val loss\n",
            "\n",
            "Epoch 24/39\n",
            "----------\n",
            "accuracy=99.35024752475248\n",
            "accuracy=99.28482587064677\n",
            "accuracy=99.14867109634551\n",
            "accuracy=99.08821695760598\n",
            "accuracy=98.98328343313374\n",
            "accuracy=98.94966722129784\n",
            "accuracy=98.96130527817404\n",
            "accuracy=98.9895443196005\n",
            "accuracy=98.95255271920088\n",
            "accuracy=98.95104895104895\n",
            "accuracy=98.91575840145322\n",
            "accuracy=98.89935470441299\n",
            "train Loss: 0.0012 train Acc: 98.8950\n",
            "accuracy=98.85519801980197\n",
            "accuracy=98.84950248756219\n",
            "accuracy=98.93064784053156\n",
            "val Loss: 0.0014 val Acc: 98.9100\n",
            "model did not improve from 0.0014 val loss\n",
            "Epoch    24: reducing learning rate of group 0 to 1.0000e-05.\n",
            "\n",
            "Epoch 25/39\n",
            "----------\n",
            "accuracy=98.82425742574257\n",
            "accuracy=99.0360696517413\n",
            "accuracy=98.97217607973423\n",
            "accuracy=98.83104738154613\n",
            "accuracy=98.85853293413173\n",
            "accuracy=98.87167221297837\n",
            "accuracy=98.86768901569187\n",
            "accuracy=98.86860174781523\n",
            "accuracy=98.88665371809101\n",
            "accuracy=98.91358641358642\n",
            "accuracy=98.93562670299727\n",
            "accuracy=98.9253746877602\n",
            "train Loss: 0.0012 train Acc: 98.9300\n",
            "accuracy=98.88613861386139\n",
            "accuracy=98.88059701492537\n",
            "accuracy=98.90988372093024\n",
            "val Loss: 0.0014 val Acc: 98.9500\n",
            "model did not improve from 0.0014 val loss\n",
            "\n",
            "Epoch 26/39\n",
            "----------\n",
            "accuracy=99.00990099009901\n",
            "accuracy=99.06716417910448\n",
            "accuracy=99.10714285714286\n",
            "accuracy=99.04925187032418\n",
            "accuracy=98.95833333333333\n",
            "accuracy=98.94446755407654\n",
            "accuracy=98.96130527817404\n",
            "accuracy=98.92322097378278\n",
            "accuracy=98.89359045504995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-92e380386a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-401d8ae5a731>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeYwJo99338q",
        "colab_type": "text"
      },
      "source": [
        "INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2NjlRWu9bW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! nvidia-smi\n",
        "model=MyResNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uikRbB_3TW2E",
        "colab_type": "code",
        "outputId": "24967b8e-083e-4052-8231-6432bc1bbf1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model = efficientnet(5,10)\n",
        "model=model.to(device)\n",
        "#CHANGE THE FILE NAME TO POINT TO THE CHECKPOINT TO BE LOADED\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/res50_18.pth.tar\")[\"state_dict\"])\n",
        "model.eval()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyResNet(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (6): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (7): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (8): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (9): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (10): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (11): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (12): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (13): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (14): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (15): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (16): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (17): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (18): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (19): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (20): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (21): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (22): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Dropout(p=0.4, inplace=False)\n",
              "      (3): Linear(in_features=512, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbjbrhsE4JCV",
        "colab_type": "text"
      },
      "source": [
        "TEST DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC6dPiPhTWwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MytestDataset(Dataset):\n",
        "    def __init__(self, data, transform=None,transform1=None):\n",
        "        self.data = data\n",
        "#         self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        self.transform1=transform1\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "#         y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            x=x.repeat(3,1,1)\n",
        "        if self.transform1:\n",
        "            x=self.transform1(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "testdataset = MytestDataset(test_img,transform=transforms2,transform1=transforms3)\n",
        "testloader = DataLoader(\n",
        "    testdataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8CjQW1r4NkI",
        "colab_type": "text"
      },
      "source": [
        "CREATING CSV FOR SUBMISSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjCckPU4TWtc",
        "colab_type": "code",
        "outputId": "68837420-0d94-41c0-8b4a-9aee42e59ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ids=[]\n",
        "labels=[]\n",
        "for batch_idx, data in enumerate(testloader):\n",
        "    ids.append(batch_idx)\n",
        "    data=data.to(device)\n",
        "    outputs=model(data)\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "    labels.append(preds.item())\n",
        "print(batch_idx)\n",
        "out_df=pd.DataFrame({'Id':ids,\n",
        "                    'Label':labels})\n",
        "order=['Id','Label']\n",
        "out_df[order].to_csv('/content/drive/My Drive/modifiedmnist/test.csv',index=False)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISx6x7gFXZno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}